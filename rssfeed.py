# -*- coding: utf-8 -*-
"""RSSFeed.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14kwHkHzNSjkaSRHR8nyJALWlXt-Hangl
"""

pip install feedparser

"""# **[Python - Reading RSS feed](https://www.tutorialspoint.com/python/python_reading_rss_feed.htm)**"""

#https://www.tutorialspoint.com/python/python_reading_rss_feed.htm
import feedparser
NewsFeed = feedparser.parse("https://timesofindia.indiatimes.com/rssfeedstopstories.cms")
entry = NewsFeed.entries[1]

print (entry.keys())

"""# **Feed Title and Posts**"""

import feedparser

NewsFeed = feedparser.parse("https://timesofindia.indiatimes.com/rssfeedstopstories.cms")

print ('Number of RSS posts :', len(NewsFeed.entries))

entry = NewsFeed.entries[1]
print ('Post Title :',entry.title)

"""# **Feed Details**"""

import feedparser

NewsFeed = feedparser.parse("https://timesofindia.indiatimes.com/rssfeedstopstories.cms")

entry = NewsFeed.entries[1]

print (entry.published)
print ("******")
print (entry.summary)
print ("------News Link--------")
print (entry.link)

print (entry.description)
print (entry.sumdescriptionmary)

d = feedparser.parse('http://www.reddit.com/r/python/.rss')
print (d.entries)

"""# [Using Feedparser in Python](https://www.pythonforbeginners.com/feedparser/using-feedparser-in-python)"""

d = feedparser.parse('https://www.reddit.com/r/StockMarket/.rss')
print (d.entries) #This is a list
print (d.feed)

print (d['feed']['title']) #Prints the title
print (d['feed']['link'])  #Prints the link

print (len(d['entries']))

print (d['entries'][0]['title'])

print (d.version)
print (d.headers)
print (d.headers.get('content-type'))

"""# [A Python script to read RSS feeds (and much more)**bold text**](https://alvinalexander.com/python/python-script-read-rss-feeds-database)"""

import feedparser
import time
from subprocess import check_output
import sys

#feed_name = 'TRIBUNE'
#url = 'http://chicagotribune.feedsportal.com/c/34253/f/622872/index.rss'

feed_name = sys.argv[1]
url = sys.argv[2]

db = '/var/www/radio/data/feeds.db'
limit = 12 * 3600 * 1000

#
# function to get the current time
#
current_time_millis = lambda: int(round(time.time() * 1000))
current_timestamp = current_time_millis()

def post_is_in_db(title):
    with open(db, 'r') as database:
        for line in database:
            if title in line:
                return True
    return False

# return true if the title is in the database with a timestamp > limit
def post_is_in_db_with_old_timestamp(title):
    with open(db, 'r') as database:
        for line in database:
            if title in line:
                ts_as_string = line.split('|', 1)[1]
                ts = long(ts_as_string)
                if current_timestamp - ts > limit:
                    return True
    return False

#
# get the feed data from the url
#
feed = feedparser.parse(url)

#
# figure out which posts to print
#
posts_to_print = []
posts_to_skip = []

for post in feed.entries:
    # if post is already in the database, skip it
    # TODO check the time
    title = post.title
    if post_is_in_db_with_old_timestamp(title):
        posts_to_skip.append(title)
    else:
        posts_to_print.append(title)
    
#
# add all the posts we're going to print to the database with the current timestamp
# (but only if they're not already in there)
#
#f = open(db, 'a')
#for title in posts_to_print:
#    if not post_is_in_db(title):
#        f.write(title + "|" + str(current_timestamp) + "\n")
#f.close





#
# output all of the new posts
#
count = 1
blockcount = 1
for title in posts_to_print:
    if count % 5 == 1:
        print("\n" + time.strftime("%a, %b %d %I:%M %p") + '  ((( ' + feed_name + ' - ' + str(blockcount) + ' )))')
        print("-----------------------------------------\n")
        blockcount += 1
    print(title + "\n")
    count += 1

print ("I Don't know why the code^^^ isn't printing or doing anything")
print (url)

"""# **[feedparser 5.2.0 documentation](https://pythonhosted.org/feedparser/introduction.html)**"""

#import feedparser
#d = feedparser.parse('http://feedparser.org/docs/examples/atom10.xml')
#print (d['feed']['title'])

"""# [Python Tutorial: How to Parse and Combine RSS News headlines using feedparser](https://jcutrer.com/python/python-tutorial-howto-parse-rss-headlines)"""

# Function to fetch the rss feed and return the parsed RSS
def parseRSS( rss_url ):
    return feedparser.parse( rss_url ) 
    
# Function grabs the rss feed headlines (titles) and returns them as a list
def getHeadlines( rss_url ):
    headlines = []
    
    feed = parseRSS( rss_url )
    for newsitem in feed['items']:
        headlines.append(newsitem['title'])
    
    return headlines
 
# A list to hold all headlines
allheadlines = []
 
# List of RSS feeds that we will fetch and combine
newsurls = {
    'apnews':           'http://hosted2.ap.org/atom/APDEFAULT/3d281c11a96b4ad082fe88aa0db04305',
    'googlenews':       'https://news.google.com/news/rss/?hl=en&amp;ned=us&amp;gl=US',
    'yahoonews':        'http://news.yahoo.com/rss/',
    'cbnc':             'https://www.cnbc.com/id/100003114/device/rss/rss.html',
    'espn':             'http://www.espn.com/espn/rss/news',
    'nytimes_environment':  "http://rss.nytimes.com/services/xml/rss/nyt/EnergyEnvironment.xml",
    'nytimes_business':     "http://rss.nytimes.com/services/xml/rss/nyt/Business.xml",
    'nytimes_economy':      "http://rss.nytimes.com/services/xml/rss/nyt/Economy.xml",
    'nytimes_dealbook':     "http://rss.nytimes.com/services/xml/rss/nyt/Economy.xml",
    'reddit_stocks': "https://www.reddit.com/r/stocks/.rss",
    'reddit_stockMarket': "https://www.reddit.com/r/StockMarket/.rss"
}
 
# Iterate over the feed urls
for key,url in newsurls.items():
    # Call getHeadlines() and combine the returned headlines with allheadlines
    allheadlines.extend( getHeadlines( url ) )
 
 
# Iterate over the allheadlines list and print each headline
for hl in allheadlines:
    print(hl)

# end of code

NewsFeed = feedparser.parse("http://www.espn.com/espn/rss/news")

entry = NewsFeed.entries[10]
#print (len(entry))

print (entry.keys())
print ('\n')


print (entry.title)
print (entry.published)
print ("******")
print (entry.summary)
print ("------News Link--------")
print (entry.link)
print ('\n')

from google.colab import files
import feedparser
import csv


list_of_hl = []

for hl in allheadlines:
    list_of_hl.append(hl)

print (list_of_hl)

###

from google.colab import files


with open('RSS_Feeds_For_presentation.txt', 'w') as f:
  for i in range(len(allheadlines)):
    f.write(list_of_hl[i])
    f.write("/n")

#files.download('RSS_Feeds_For_presentation.txt')

#-------------------
"""
import csv
 
with open('example.csv', 'wb') as csvfile:
    filewriter = csv.writer(csvfile, delimiter=',',
                            quotechar='|', quoting=csv.QUOTE_MINIMAL)
    filewriter.writerow(['Name', 'Profession'])
    filewriter.writerow(['Derek', 'Software Developer'])
    filewriter.writerow(['Steve', 'Software Developer'])
    filewriter.writerow(['Paul', 'Manager'])
"""

"""# *** Resources***
---
Feedparser

1.   https://pythonhosted.org/feedparser/


CSV
*   [External data: Drive, Sheets, and Cloud Storage](https://colab.research.google.com/notebooks/io.ipynb)
*   [csv â€” CSV File Reading and Writing](https://docs.python.org/3/library/csv.html)
*   [Python Spot](https://pythonspot.com/files-spreadsheets-csv/)

RSS Feeds

1.   https://www.cnbc.com/rss-feeds/
"""

